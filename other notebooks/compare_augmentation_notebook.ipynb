{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation Impact Comparison\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook compares model performance **with** and **without** data augmentation to demonstrate the benefits.\n",
    "\n",
    "### What This Does:\n",
    "\n",
    "1. **Baseline Model**: Train on original data only (no augmentation)\n",
    "2. **Augmented Model**: Train with full augmentation pipeline (7√ó multiplier)\n",
    "3. **Compare Results**: Side-by-side comparison of:\n",
    "   - Validation accuracy\n",
    "   - Per-class performance\n",
    "   - Training curves\n",
    "   - Confusion matrices\n",
    "\n",
    "### Expected Outcomes:\n",
    "\n",
    "- **More training data**: Augmentation increases training samples from ~350 to ~2,500\n",
    "- **Better accuracy**: Expected improvement of 5-15 percentage points\n",
    "- **Better generalization**: Reduced overfitting, better real-world performance\n",
    "- **Balanced performance**: More consistent accuracy across all classes\n",
    "\n",
    "**‚è±Ô∏è Time Required**: ~1-2 hours (both models need to train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q librosa soundfile tensorflow scikit-learn pandas matplotlib\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all modules\n",
    "import config\n",
    "import data_loader\n",
    "import preprocessing\n",
    "import augmentation\n",
    "import model as model_module\n",
    "import train\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Print configuration\n",
    "config.print_config_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Baseline Model (No Augmentation)\n",
    "\n",
    "Train a model using **only original data** with no augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"PART 1: BASELINE MODEL - NO AUGMENTATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load raw data\n",
    "species_data = data_loader.load_species_data()\n",
    "background_data = data_loader.load_background_data()\n",
    "\n",
    "print(\"\\nüìä Creating dataset WITHOUT augmentation...\")\n",
    "\n",
    "# Prepare dataset without augmentation\n",
    "X_all = []\n",
    "y_all = []\n",
    "\n",
    "# Label mapping\n",
    "label_map = {species: i for i, species in enumerate(config.CLASS_NAMES[:-1])}\n",
    "label_map['Background'] = len(label_map)\n",
    "\n",
    "# Process species\n",
    "for species_name, audio_list in species_data.items():\n",
    "    print(f\"   Processing {species_name}...\")\n",
    "    species_label = label_map[species_name]\n",
    "    \n",
    "    for audio, _ in audio_list:\n",
    "        mel_spec = preprocessing.audio_to_melspectrogram(audio)\n",
    "        spec_norm = preprocessing.normalize_spectrogram(mel_spec)\n",
    "        spec_resized = preprocessing.resize_spectrogram(spec_norm)\n",
    "        rgb_image = preprocessing.spectrogram_to_rgb(spec_resized)\n",
    "        \n",
    "        X_all.append(rgb_image)\n",
    "        y_all.append(species_label)\n",
    "\n",
    "# Process background\n",
    "print(\"   Processing Background...\")\n",
    "for audio, _ in background_data:\n",
    "    mel_spec = preprocessing.audio_to_melspectrogram(audio)\n",
    "    spec_norm = preprocessing.normalize_spectrogram(mel_spec)\n",
    "    spec_resized = preprocessing.resize_spectrogram(spec_norm)\n",
    "    rgb_image = preprocessing.spectrogram_to_rgb(spec_resized)\n",
    "    \n",
    "    X_all.append(rgb_image)\n",
    "    y_all.append(label_map['Background'])\n",
    "\n",
    "# Convert to arrays and normalize\n",
    "X_all = np.array(X_all)\n",
    "y_all = np.array(y_all)\n",
    "X_all = preprocessing.preprocess_for_model(X_all)\n",
    "\n",
    "print(f\"\\n Total samples: {len(X_all)}\")\n",
    "\n",
    "# Split into train/val\n",
    "X_train_base, X_val_base, y_train_base, y_val_base = train_test_split(\n",
    "    X_all, y_all,\n",
    "    test_size=config.VALIDATION_SPLIT,\n",
    "    random_state=config.RANDOM_SEED,\n",
    "    stratify=y_all\n",
    ")\n",
    "\n",
    "print(f\"\\n   Training: {len(X_train_base)} samples\")\n",
    "print(f\"   Validation: {len(X_val_base)} samples\")\n",
    "\n",
    "# Show distribution\n",
    "print(\"\\n   Class Distribution:\")\n",
    "for i, name in enumerate(config.CLASS_NAMES):\n",
    "    count = np.sum(y_all == i)\n",
    "    print(f\"      {name}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model\n",
    "print(\"\\n Training Baseline Model...\\n\")\n",
    "\n",
    "model_baseline = model_module.create_and_compile_model()\n",
    "\n",
    "# Calculate class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "classes = np.unique(y_train_base)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y_train_base)\n",
    "class_weights_base = dict(enumerate(weights))\n",
    "\n",
    "# Callbacks\n",
    "callbacks_base = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=config.PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train\n",
    "history_baseline = model_baseline.fit(\n",
    "    X_train_base, y_train_base,\n",
    "    validation_data=(X_val_base, y_val_base),\n",
    "    epochs=config.EPOCHS,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    class_weight=class_weights_base,\n",
    "    callbacks=callbacks_base,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n Baseline model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline\n",
    "print(\"\\n  Baseline Model Evaluation:\\n\")\n",
    "results_baseline = model_baseline.evaluate(X_val_base, y_val_base, verbose=0)\n",
    "\n",
    "print(f\"   Validation Loss: {results_baseline[0]:.4f}\")\n",
    "print(f\"   Validation Accuracy: {results_baseline[1]:.4f}\")\n",
    "print(f\"   Top-2 Accuracy: {results_baseline[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Augmented Model (With Data Augmentation)\n",
    "\n",
    "Train a model using the **full augmentation pipeline** (7√ó multiplier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the standard training pipeline with augmentation\n",
    "X_train_aug, X_val_aug, y_train_aug, y_val_aug, _ = train.prepare_dataset()\n",
    "\n",
    "print(f\"   Training: {len(X_train_aug)} samples\")\n",
    "print(f\"   Validation: {len(X_val_aug)} samples\")\n",
    "print(f\"\\n   Data multiplier: {len(X_train_aug) / len(X_train_base):.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train augmented model\n",
    "print(\"\\n Training Augmented Model...\\n\")\n",
    "\n",
    "model_augmented = model_module.create_and_compile_model()\n",
    "\n",
    "# Calculate class weights\n",
    "classes = np.unique(y_train_aug)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y_train_aug)\n",
    "class_weights_aug = dict(enumerate(weights))\n",
    "\n",
    "# Callbacks\n",
    "callbacks_aug = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=config.PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train\n",
    "history_augmented = model_augmented.fit(\n",
    "    X_train_aug, y_train_aug,\n",
    "    validation_data=(X_val_aug, y_val_aug),\n",
    "    epochs=config.EPOCHS,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    class_weight=class_weights_aug,\n",
    "    callbacks=callbacks_aug,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate augmented\n",
    "print(\"\\n Augmented Model Evaluation:\\n\")\n",
    "results_augmented = model_augmented.evaluate(X_val_aug, y_val_aug, verbose=0)\n",
    "\n",
    "print(f\"   Validation Loss: {results_augmented[0]:.4f}\")\n",
    "print(f\"   Validation Accuracy: {results_augmented[1]:.4f}\")\n",
    "print(f\"   Top-2 Accuracy: {results_augmented[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Comprehensive Comparison\n",
    "\n",
    "Compare both models side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"{'Metric':<25s} {'Baseline':>15s} {'Augmented':>15s} {'Improvement':>15s}\")\n",
    "\n",
    "# Accuracy\n",
    "acc_diff = (results_augmented[1] - results_baseline[1]) * 100\n",
    "print(f\"{'Validation Accuracy':<25s} {results_baseline[1]:>14.4f} {results_augmented[1]:>14.4f} {acc_diff:>+14.2f}pp\")\n",
    "\n",
    "# Loss\n",
    "loss_diff = ((results_baseline[0] - results_augmented[0]) / results_baseline[0]) * 100\n",
    "print(f\"{'Validation Loss':<25s} {results_baseline[0]:>14.4f} {results_augmented[0]:>14.4f} {loss_diff:>+14.2f}%\")\n",
    "\n",
    "# Top-2 accuracy\n",
    "top2_diff = (results_augmented[2] - results_baseline[2]) * 100\n",
    "print(f\"{'Top-2 Accuracy':<25s} {results_baseline[2]:>14.4f} {results_augmented[2]:>14.4f} {top2_diff:>+14.2f}pp\")\n",
    "\n",
    "# Training samples\n",
    "print(f\"{'Training Samples':<25s} {len(X_train_base):>14d} {len(X_train_aug):>14d} {((len(X_train_aug)/len(X_train_base)-1)*100):>+14.1f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class comparison\n",
    "print(\"\\n Per-Class Performance:\\n\")\n",
    "\n",
    "y_pred_base = model_baseline.predict(X_val_base, verbose=0)\n",
    "y_pred_base_classes = np.argmax(y_pred_base, axis=1)\n",
    "\n",
    "y_pred_aug = model_augmented.predict(X_val_aug, verbose=0)\n",
    "y_pred_aug_classes = np.argmax(y_pred_aug, axis=1)\n",
    "\n",
    "print(f\"{'Class':<30s} {'Baseline Acc':>15s} {'Aug Acc':>15s} {'Improvement':>15s}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for i, class_name in enumerate(config.CLASS_NAMES):\n",
    "    # Baseline\n",
    "    mask_base = y_val_base == i\n",
    "    if np.sum(mask_base) > 0:\n",
    "        acc_base = np.sum((y_pred_base_classes == i) & mask_base) / np.sum(mask_base)\n",
    "    else:\n",
    "        acc_base = 0\n",
    "    \n",
    "    # Augmented\n",
    "    mask_aug = y_val_aug == i\n",
    "    if np.sum(mask_aug) > 0:\n",
    "        acc_aug = np.sum((y_pred_aug_classes == i) & mask_aug) / np.sum(mask_aug)\n",
    "    else:\n",
    "        acc_aug = 0\n",
    "    \n",
    "    improvement = (acc_aug - acc_base) * 100\n",
    "    \n",
    "    print(f\"{class_name:<30s} {acc_base:>14.2%} {acc_aug:>14.2%} {improvement:>+14.2f}pp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Training curves comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history_baseline.history['accuracy'], label='Baseline Train', linestyle='--', alpha=0.7, linewidth=2)\n",
    "axes[0].plot(history_baseline.history['val_accuracy'], label='Baseline Val', linestyle='--', alpha=0.7, linewidth=2)\n",
    "axes[0].plot(history_augmented.history['accuracy'], label='Augmented Train', linewidth=2.5)\n",
    "axes[0].plot(history_augmented.history['val_accuracy'], label='Augmented Val', linewidth=2.5)\n",
    "axes[0].set_title('Training Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history_baseline.history['loss'], label='Baseline Train', linestyle='--', alpha=0.7, linewidth=2)\n",
    "axes[1].plot(history_baseline.history['val_loss'], label='Baseline Val', linestyle='--', alpha=0.7, linewidth=2)\n",
    "axes[1].plot(history_augmented.history['loss'], label='Augmented Train', linewidth=2.5)\n",
    "axes[1].plot(history_augmented.history['val_loss'], label='Augmented Val', linewidth=2.5)\n",
    "axes[1].set_title('Training Loss Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/MyDrive/chimp-audio/outputs/visualizations/comparison_curves.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Baseline confusion matrix\n",
    "cm_base = confusion_matrix(y_val_base, y_pred_base_classes)\n",
    "cm_base_norm = cm_base.astype('float') / cm_base.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "im1 = axes[0].imshow(cm_base_norm, interpolation='nearest', cmap='Blues')\n",
    "axes[0].set_title('Baseline Model - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "tick_marks = np.arange(len(config.CLASS_NAMES))\n",
    "axes[0].set_xticks(tick_marks)\n",
    "axes[0].set_yticks(tick_marks)\n",
    "axes[0].set_xticklabels([c[:10] for c in config.CLASS_NAMES], rotation=45, ha='right')\n",
    "axes[0].set_yticklabels([c[:10] for c in config.CLASS_NAMES])\n",
    "\n",
    "thresh = cm_base_norm.max() / 2.\n",
    "for i in range(len(config.CLASS_NAMES)):\n",
    "    for j in range(len(config.CLASS_NAMES)):\n",
    "        axes[0].text(j, i, f'{cm_base_norm[i, j]:.2f}',\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm_base_norm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Augmented confusion matrix\n",
    "cm_aug = confusion_matrix(y_val_aug, y_pred_aug_classes)\n",
    "cm_aug_norm = cm_aug.astype('float') / cm_aug.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "im2 = axes[1].imshow(cm_aug_norm, interpolation='nearest', cmap='Greens')\n",
    "axes[1].set_title('Augmented Model - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "axes[1].set_xticks(tick_marks)\n",
    "axes[1].set_yticks(tick_marks)\n",
    "axes[1].set_xticklabels([c[:10] for c in config.CLASS_NAMES], rotation=45, ha='right')\n",
    "axes[1].set_yticklabels([c[:10] for c in config.CLASS_NAMES])\n",
    "\n",
    "thresh = cm_aug_norm.max() / 2.\n",
    "for i in range(len(config.CLASS_NAMES)):\n",
    "    for j in range(len(config.CLASS_NAMES)):\n",
    "        axes[1].text(j, i, f'{cm_aug_norm[i, j]:.2f}',\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm_aug_norm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/MyDrive/chimp-audio/outputs/visualizations/comparison_confusion.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "import os\n",
    "\n",
    "model_baseline.save(os.path.join(config.MODEL_SAVE_DIR, 'baseline_no_augmentation.h5'))\n",
    "model_augmented.save(os.path.join(config.MODEL_SAVE_DIR, 'model_with_augmentation.h5'))\n",
    "\n",
    "print(f\"   Baseline: {config.MODEL_SAVE_DIR}/baseline_no_augmentation.h5\")\n",
    "print(f\"   Augmented: {config.MODEL_SAVE_DIR}/model_with_augmentation.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
