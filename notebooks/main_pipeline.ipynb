{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primate Vocalization Detection Pipeline\n",
    "## Reproducible End-to-End System\n",
    "\n",
    "This notebook demonstrates a complete pipeline for detecting primate vocalizations in long audio recordings.\n",
    "\n",
    "### Pipeline Overview:\n",
    "1. **Configuration** - Set all parameters\n",
    "2. **Data Loading** - Load species clips and background noise\n",
    "3. **Preprocessing** - Convert to mel-spectrograms\n",
    "4. **Data Augmentation** - Apply augmentation strategies\n",
    "5. **Model Training** - Train VGG19-based classifier\n",
    "6. **Detection** - Detect vocalizations in long audio files\n",
    "7. **Visualization** - Create visualizations and reports\n",
    "\n",
    "### Key Features:\n",
    "- âœ… Modular design - easy to add new species\n",
    "- âœ… Configurable parameters - adjust without code changes\n",
    "- âœ… Reproducible results - fixed random seeds\n",
    "- âœ… GPU-accelerated - optimized for Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q librosa soundfile tensorflow scikit-learn pandas matplotlib\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "All parameters are defined in `config.py`. To add a new species or change parameters, simply edit the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all modules\n",
    "import config\n",
    "import data_loader\n",
    "import preprocessing\n",
    "import augmentation\n",
    "import model as model_module\n",
    "import train\n",
    "import detection\n",
    "import utils\n",
    "\n",
    "# Print configuration summary\n",
    "config.print_config_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ To Add a New Species:\n",
    "\n",
    "1. Add audio files to Google Drive: `chimp-audio/audio/new_species_folder/`\n",
    "2. Edit `config.py` and add to `SPECIES_FOLDERS`:\n",
    "   ```python\n",
    "   SPECIES_FOLDERS = {\n",
    "       'Cercocebus_torquatus': 'Cercocebus torquatus hack 5s',\n",
    "       'Colobus_guereza': 'Colobus guereza Clips 5s',\n",
    "       'New_Species': 'new_species_folder',  # â† Add this line\n",
    "   }\n",
    "   ```\n",
    "3. Re-run the notebook - everything will automatically adjust!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Exploration\n",
    "\n",
    "Load all audio files and verify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load species data\n",
    "species_data = data_loader.load_species_data()\n",
    "\n",
    "# Load background data\n",
    "background_data = data_loader.load_background_data()\n",
    "\n",
    "# Print summary\n",
    "data_loader.print_data_summary(species_data, background_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Listen to a sample\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Play a Cercocebus sample\n",
    "if 'Cercocebus_torquatus' in species_data:\n",
    "    sample_audio, sample_path = species_data['Cercocebus_torquatus'][0]\n",
    "    print(f\"Playing: {sample_path}\")\n",
    "    ipd.display(ipd.Audio(sample_audio, rate=config.SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Complete Training Pipeline\n",
    "\n",
    "This runs the entire training process:\n",
    "- Data preprocessing\n",
    "- Augmentation\n",
    "- Model training\n",
    "- Evaluation\n",
    "\n",
    "**This will take some time (~30-60 minutes depending on data size)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run complete training pipeline\n",
    "trained_model = train.run_complete_training_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Detection on Long Audio\n",
    "\n",
    "Now we'll use the trained model to detect primate vocalizations in long audio files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Test on First Long Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of long audio files\n",
    "long_audio_files = data_loader.get_long_audio_files()\n",
    "\n",
    "print(f\"Found {len(long_audio_files)} long audio files:\")\n",
    "for i, file in enumerate(long_audio_files[:10], 1):  # Show first 10\n",
    "    print(f\"  {i}. {os.path.basename(file)}\")\n",
    "if len(long_audio_files) > 10:\n",
    "    print(f\"  ... and {len(long_audio_files) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect in the first long audio file\n",
    "first_audio = long_audio_files[0]\n",
    "print(f\"Processing: {os.path.basename(first_audio)}\")\n",
    "\n",
    "detections_df = detection.detect_in_long_audio(\n",
    "    trained_model, \n",
    "    first_audio,\n",
    "    confidence_threshold=config.DETECTION_CONFIDENCE_THRESHOLD\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nğŸ“‹ Detection Results:\")\n",
    "if len(detections_df) > 0:\n",
    "    display(detections_df.head(20))  # Show first 20 detections\n",
    "else:\n",
    "    print(\"No detections found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detections to CSV\n",
    "csv_path = detection.save_detections(\n",
    "    detections_df, \n",
    "    os.path.basename(first_audio)\n",
    ")\n",
    "print(f\"Detections saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Visualize Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "utils.visualize_detection_results(\n",
    "    first_audio,\n",
    "    detections_df,\n",
    "    save_path=None,  # Set to path to save, None to just display\n",
    "    show_spectrogram=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Process All Long Audio Files\n",
    "\n",
    "**Warning: This may take a long time if you have many files!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all long audio files\n",
    "# Comment out this cell if you only want to process the first file\n",
    "\n",
    "all_detections = detection.process_all_long_audio_files(\n",
    "    trained_model,\n",
    "    confidence_threshold=config.DETECTION_CONFIDENCE_THRESHOLD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis & Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detection statistics\n",
    "utils.print_detection_statistics(all_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "summary_path = os.path.join(config.DETECTION_OUTPUT_DIR, 'detection_summary.csv')\n",
    "summary_df = utils.create_detection_summary_report(all_detections, summary_path)\n",
    "\n",
    "print(\"\\nğŸ“Š Summary Report:\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for all files\n",
    "utils.visualize_all_detections(all_detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optional: Extract Detected Clips\n",
    "\n",
    "Extract audio clips for each detection for manual validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract clips from first audio file\n",
    "clips_output_dir = os.path.join(config.OUTPUT_ROOT, 'detected_clips')\n",
    "\n",
    "if len(detections_df) > 0:\n",
    "    utils.extract_detected_audio_clips(\n",
    "        first_audio,\n",
    "        detections_df,\n",
    "        clips_output_dir,\n",
    "        padding=0.5  # Add 0.5s padding around each detection\n",
    "    )\n",
    "else:\n",
    "    print(\"No detections to extract.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Persistence\n",
    "\n",
    "The best model is automatically saved during training. You can also manually save/load models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model was saved during training\n",
    "best_model_path = os.path.join(config.MODEL_SAVE_DIR, 'best_model.h5')\n",
    "print(f\"Best model saved at: {best_model_path}\")\n",
    "\n",
    "# To load the model later:\n",
    "# loaded_model = model_module.load_trained_model(best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Adjust Detection Threshold (Optional)\n",
    "\n",
    "If you want to experiment with different confidence thresholds without retraining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different thresholds\n",
    "thresholds = [0.5, 0.7, 0.9]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Testing threshold: {threshold}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    detections = detection.detect_in_long_audio(\n",
    "        trained_model,\n",
    "        first_audio,\n",
    "        confidence_threshold=threshold\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nFound {len(detections)} detections with threshold {threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### ğŸ“ Output Files Generated:\n",
    "\n",
    "```\n",
    "drive/MyDrive/chimp-audio/outputs/\n",
    "â”œâ”€â”€ models/\n",
    "â”‚   â”œâ”€â”€ best_model.h5              # Trained model\n",
    "â”‚   â”œâ”€â”€ training_history.json      # Training metrics\n",
    "â”‚   â””â”€â”€ training_history.png       # Training curves\n",
    "â”œâ”€â”€ detections/\n",
    "â”‚   â”œâ”€â”€ *_detections.csv           # Detection results (CSV)\n",
    "â”‚   â””â”€â”€ detection_summary.csv      # Overall summary\n",
    "â”œâ”€â”€ visualizations/\n",
    "â”‚   â””â”€â”€ *_visualization.png        # Waveform/spectrogram plots\n",
    "â””â”€â”€ detected_clips/\n",
    "    â””â”€â”€ *.wav                      # Extracted audio clips\n",
    "```\n",
    "\n",
    "### ğŸ”„ To Add New Species or Data:\n",
    "\n",
    "1. Add new audio files to appropriate folders in Google Drive\n",
    "2. Update `config.py` (add to `SPECIES_FOLDERS` or `BACKGROUND_FOLDERS`)\n",
    "3. Re-run this notebook\n",
    "\n",
    "That's it! The pipeline is fully automated and reproducible. ğŸ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
