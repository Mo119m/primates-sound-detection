{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primate Vocalization Detection Pipeline\n",
    "## Reproducible End-to-End System\n",
    "\n",
    "This notebook demonstrates a complete pipeline for detecting primate vocalizations in long audio recordings.\n",
    "\n",
    "### Pipeline Overview:\n",
    "1. **Configuration** - Set all parameters\n",
    "2. **Data Loading** - Load species clips and background noise\n",
    "3. **Preprocessing** - Convert to mel-spectrograms\n",
    "4. **Data Augmentation** - Apply augmentation strategies\n",
    "5. **Model Training** - Train VGG19-based classifier\n",
    "6. **Detection** - Detect vocalizations in long audio files\n",
    "7. **Analysis & Reporting** - Create visualizations and reports\n",
    "8. **Hard Negative Mining** - Improve model by learning from mistakes (NEW!)\n",
    "9. **Optional: Extract Clips** - Extract detected clips\n",
    "\n",
    "### Key Features:\n",
    "-  Modular design - easy to add new species\n",
    "-  Configurable parameters - adjust without code changes\n",
    "-  Reproducible results - fixed random seeds\n",
    "-  GPU-accelerated - optimized for Google Colab\n",
    "-  Iterative improvement - hard negative mining for better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q librosa soundfile tensorflow scikit-learn pandas matplotlib\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "All parameters are defined in `config.py`. To add a new species or change parameters, simply edit the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all modules\n",
    "import config\n",
    "import data_loader\n",
    "import preprocessing\n",
    "import augmentation\n",
    "import model as model_module\n",
    "import train\n",
    "import detection\n",
    "import utils\n",
    "\n",
    "# Print configuration summary\n",
    "config.print_config_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Add a New Species:\n",
    "\n",
    "1. Add audio files to Google Drive: `chimp-audio/audio/new_species_folder/`\n",
    "2. Edit `config.py` and add to `SPECIES_FOLDERS`:\n",
    "   ```python\n",
    "   SPECIES_FOLDERS = {\n",
    "       'Cercocebus_torquatus': 'Cercocebus torquatus hack 5s',\n",
    "       'Colobus_guereza': 'Colobus guereza Clips 5s',\n",
    "       'New_Species': 'new_species_folder',  # ← Add this line\n",
    "   }\n",
    "   ```\n",
    "3. Re-run the notebook - everything will automatically adjust!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Exploration\n",
    "\n",
    "Load all audio files and verify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load species data\n",
    "species_data = data_loader.load_species_data()\n",
    "\n",
    "# Load background data\n",
    "background_data = data_loader.load_background_data()\n",
    "\n",
    "# Print summary\n",
    "data_loader.print_data_summary(species_data, background_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Complete Training Pipeline\n",
    "\n",
    "This runs the entire training process:\n",
    "- Data preprocessing\n",
    "- Augmentation\n",
    "- Model training\n",
    "- Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run complete training pipeline\n",
    "trained_model = train.run_complete_training_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Detection on Long Audio\n",
    "\n",
    "Now we'll use the trained model to detect primate vocalizations in long audio files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Test on First Long Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of long audio files\n",
    "long_audio_files = data_loader.get_long_audio_files()\n",
    "\n",
    "print(f\"Found {len(long_audio_files)} long audio files:\")\n",
    "for i, file in enumerate(long_audio_files[:10], 1):  # Show first 10\n",
    "    print(f\"  {i}. {os.path.basename(file)}\")\n",
    "if len(long_audio_files) > 10:\n",
    "    print(f\"  ... and {len(long_audio_files) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect in the first long audio file\n",
    "import os\n",
    "\n",
    "first_audio = long_audio_files[0]\n",
    "print(f\"Processing: {os.path.basename(first_audio)}\")\n",
    "\n",
    "detections_df = detection.detect_in_long_audio(\n",
    "    trained_model, \n",
    "    first_audio,\n",
    "    confidence_threshold=config.DETECTION_CONFIDENCE_THRESHOLD\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n Detection Results:\")\n",
    "if len(detections_df) > 0:\n",
    "    display(detections_df.head(20))  # Show first 20 detections\n",
    "else:\n",
    "    print(\"No detections found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detections to CSV\n",
    "csv_path = detection.save_detections(\n",
    "    detections_df, \n",
    "    os.path.basename(first_audio)\n",
    ")\n",
    "print(f\"Detections saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Visualize Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "utils.visualize_detection_results(\n",
    "    first_audio,\n",
    "    detections_df,\n",
    "    save_path=None,  # Set to path to save, None to just display\n",
    "    show_spectrogram=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Process All Long Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all long audio files\n",
    "# Comment out this cell if you only want to process the first file\n",
    "\n",
    "all_detections = detection.process_all_long_audio_files(\n",
    "    trained_model,\n",
    "    confidence_threshold=config.DETECTION_CONFIDENCE_THRESHOLD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis & Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detection statistics\n",
    "utils.print_detection_statistics(all_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "summary_path = os.path.join(config.DETECTION_OUTPUT_DIR, 'detection_summary.csv')\n",
    "summary_df = utils.create_detection_summary_report(all_detections, summary_path)\n",
    "\n",
    "print(\"\\n Summary Report:\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for all files\n",
    "utils.visualize_all_detections(all_detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hard Negative Mining - Model Improvement (**uncertain now**)\n",
    "\n",
    "### What is Hard Negative Mining?\n",
    "\n",
    "If notice many **false positives** (e.g., bird calls being classified as primate calls), you can use this to improve your model.\n",
    "\n",
    "**The Process:**\n",
    "1. Extract samples where the model is uncertain (medium confidence 0.5-0.85)\n",
    "2. Manually verify which are false positives\n",
    "3. Add verified false positives as \"hard negatives\" to training data\n",
    "4. Retrain the model\n",
    "\n",
    "**Result:** Model learns to distinguish between commonly confused sounds (e.g., bird calls vs primate calls)\n",
    "\n",
    "### When to Use This?\n",
    "\n",
    "- After initial training and detection\n",
    "- When you see many bird calls or environmental sounds misclassified\n",
    "- When one species is heavily over-represented in detections\n",
    "- To improve model precision on real-world recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Run Hard Negative Mining Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run hard negative mining\n",
    "exec(open('run_hard_negative_mining.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Manual Verification (Critical Step!)\n",
    "\n",
    "**IMPORTANT: You must do this manually in Google Drive!**\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "1. **Go to Google Drive**: `chimp-audio/audio/hard_negative_candidates/`\n",
    "\n",
    "2. **Listen to each audio file** \n",
    "\n",
    "3. **Make a decision for each file:**\n",
    "   - **DELETE** if it's an actual primate call (model is correct)\n",
    "   - **KEEP** if it's NOT a primate call (bird, insect, rain, wind, etc.)\n",
    "\n",
    "4. **Create new folder**: `chimp-audio/audio/verified_hard_negatives/`\n",
    "\n",
    "5. **MOVE** all kept files to `verified_hard_negatives/`\n",
    "\n",
    "#### What to Expect:\n",
    "- **Examples of what to keep**: Bird calls, insect sounds, rain, wind, rustling leaves\n",
    "- **Examples of what to delete**: Actual primate vocalizations\n",
    "\n",
    "\n",
    "**PAUSE HERE and complete the manual verification before continuing!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Update Configuration\n",
    "\n",
    "After you've verified and organized the files, update `config.py` to include the new hard negatives folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if verified_hard_negatives folder exists\n",
    "import os\n",
    "verified_folder = os.path.join(config.AUDIO_ROOT, 'verified_hard_negatives')\n",
    "\n",
    "if os.path.exists(verified_folder):\n",
    "    file_count = len([f for f in os.listdir(verified_folder) if f.endswith('.wav')])\n",
    "    print(f\"Found verified_hard_negatives folder with {file_count} files\")\n",
    "    print(\"\\nNow edit config.py manually!\")\n",
    "    print(\"\\nAdd to BACKGROUND_FOLDERS (around line 28-32):\")\n",
    "    print(\"\\nThen run the next cell to reload config.\")\n",
    "else:\n",
    "    print(\" verified_hard_negatives folder not found!\")\n",
    "    print(\"\\nPlease:\")\n",
    "    print(\"1. Go to Google Drive: chimp-audio/audio/\")\n",
    "    print(\"2. Create folder: verified_hard_negatives/\")\n",
    "    print(\"3. Move verified files from hard_negative_candidates/ to verified_hard_negatives/\")\n",
    "    print(\"4. Run this cell again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload config after editing\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "\n",
    "# Verify new folder is recognized\n",
    "print(\"Updated Configuration:\")\n",
    "config.print_config_summary()\n",
    "\n",
    "# Load updated data\n",
    "background_data_updated = data_loader.load_background_data()\n",
    "print(f\"\\n Total background samples: {len(background_data_updated)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Retrain with Hard Negatives\n",
    "\n",
    "Now retrain the model with the expanded background dataset that includes verified hard negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train improved model\n",
    "improved_model = train.run_complete_training_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Compare Results\n",
    "\n",
    "Test the improved model on the same audio file and compare with original results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detection with improved model\n",
    "print(f\"Testing improved model on: {os.path.basename(first_audio)}\\n\")\n",
    "\n",
    "improved_detections = detection.detect_in_long_audio(\n",
    "    improved_model,\n",
    "    first_audio,\n",
    "    confidence_threshold=config.DETECTION_CONFIDENCE_THRESHOLD\n",
    ")\n",
    "\n",
    "# Compare\n",
    "\n",
    "print(f\"\\nOriginal model detections: {len(detections_df)}\")\n",
    "print(f\"Improved model detections: {len(improved_detections)}\")\n",
    "print(f\"Change: {len(improved_detections) - len(detections_df)} ({(len(improved_detections)/len(detections_df)-1)*100:.1f}%)\")\n",
    "\n",
    "if len(detections_df) > 0:\n",
    "    print(\"\\n Original Distribution:\")\n",
    "    print(detections_df['species'].value_counts())\n",
    "\n",
    "if len(improved_detections) > 0:\n",
    "    print(\"\\n Improved Distribution:\")\n",
    "    print(improved_detections['species'].value_counts())\n",
    "    \n",
    "    print(\"\\n Average Confidence:\")\n",
    "    print(f\"Original: {detections_df['confidence'].mean():.4f}\")\n",
    "    print(f\"Improved: {improved_detections['confidence'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize improved results\n",
    "utils.visualize_detection_results(\n",
    "    first_audio,\n",
    "    improved_detections,\n",
    "    save_path=None,\n",
    "    show_spectrogram=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Save Improved Model (Optional)\n",
    "\n",
    "If you're satisfied with the improved results, save this model with a descriptive name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save improved model with descriptive name\n",
    "improved_model_path = os.path.join(config.MODEL_SAVE_DIR, 'model_v2_with_hard_negatives.h5')\n",
    "improved_model.save(improved_model_path)\n",
    "\n",
    "print(f\" Improved model saved to: {improved_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Process All Files with Improved Model (Optional)\n",
    "\n",
    "Once satisfied with the improved model, process all long audio files again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all files with improved model\n",
    "all_detections_improved = detection.process_all_long_audio_files(\n",
    "    improved_model,\n",
    "    confidence_threshold=config.DETECTION_CONFIDENCE_THRESHOLD\n",
    ")\n",
    "\n",
    "# Generate new reports\n",
    "utils.print_detection_statistics(all_detections_improved)\n",
    "\n",
    "summary_improved_path = os.path.join(config.DETECTION_OUTPUT_DIR, 'detection_summary_v2.csv')\n",
    "summary_improved_df = utils.create_detection_summary_report(all_detections_improved, summary_improved_path)\n",
    "\n",
    "print(f\"\\n Improved summary saved to: {summary_improved_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract Detected Clips\n",
    "\n",
    "Extract audio clips for each detection for manual validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract clips from first audio file\n",
    "clips_output_dir = os.path.join(config.OUTPUT_ROOT, 'detected_clips')\n",
    "\n",
    "# Choose which detections to extract:\n",
    "# Use 'improved_detections' if you've done hard negative mining\n",
    "# Use 'detections_df' for original model results\n",
    "\n",
    "detections_to_extract = improved_detections if 'improved_detections' in locals() else detections_df\n",
    "\n",
    "if len(detections_to_extract) > 0:\n",
    "    utils.extract_detected_audio_clips(\n",
    "        first_audio,\n",
    "        detections_to_extract,\n",
    "        clips_output_dir,\n",
    "        padding=0.5  # Add 0.5s padding around each detection\n",
    "    )\n",
    "else:\n",
    "    print(\"No detections to extract.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Persistence\n",
    "\n",
    "The best model is automatically saved during training. You can also manually save/load models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model was saved during training\n",
    "best_model_path = os.path.join(config.MODEL_SAVE_DIR, 'best_model.h5')\n",
    "print(f\"Best model saved at: {best_model_path}\")\n",
    "\n",
    "# If you did hard negative mining, you also have:\n",
    "if os.path.exists(improved_model_path):\n",
    "    print(f\"Improved model (v2) saved at: {improved_model_path}\")\n",
    "\n",
    "# To load a model later:\n",
    "# loaded_model = model_module.load_trained_model(best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Adjust Detection Threshold (Optional)\n",
    "\n",
    "If you want to experiment with different confidence thresholds without retraining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different thresholds\n",
    "thresholds = [0.5, 0.7, 0.9]\n",
    "\n",
    "# Use improved model if available, otherwise use original\n",
    "test_model = improved_model if 'improved_model' in locals() else trained_model\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f\"Testing threshold: {threshold}\")\n",
    "    \n",
    "    detections = detection.detect_in_long_audio(\n",
    "        test_model,\n",
    "        first_audio,\n",
    "        confidence_threshold=threshold\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nFound {len(detections)} detections with threshold {threshold}\")\n",
    "    if len(detections) > 0:\n",
    "        print(detections['species'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Output Files Generated:\n",
    "\n",
    "```\n",
    "drive/MyDrive/chimp-audio/outputs/\n",
    "├── models/\n",
    "│   ├── best_model.h5              # Initial trained model\n",
    "│   ├── model_v2_with_hard_negatives.h5  # Improved model (if you did hard negative mining)\n",
    "│   ├── training_history.json      # Training metrics\n",
    "│   └── training_history.png       # Training curves\n",
    "├── detections/\n",
    "│   ├── *_detections.csv           # Detection results (CSV)\n",
    "│   ├── detection_summary.csv      # Overall summary (v1)\n",
    "│   └── detection_summary_v2.csv   # Overall summary (v2, if improved)\n",
    "├── visualizations/\n",
    "│   └── *_visualization.png        # Waveform/spectrogram plots\n",
    "└── detected_clips/\n",
    "    └── *.wav                      # Extracted audio clips\n",
    "```\n",
    "\n",
    "### Workflow Summary:\n",
    "\n",
    "**Standard workflow:**\n",
    "1. Setup → Configure → Load Data → Train → Detect → Analyze\n",
    "\n",
    "**With Hard Negative Mining (Recommended):**\n",
    "1. Setup → Configure → Load Data → Train → Detect → Analyze\n",
    "2. **Hard Negative Mining** → Manual Verification → Update Config → Retrain\n",
    "3. Compare Results → Use Improved Model for Production\n",
    "\n",
    "### To Add New Species or Data:\n",
    "\n",
    "1. Add new audio files to appropriate folders in Google Drive\n",
    "2. Update `config.py` (add to `SPECIES_FOLDERS` or `BACKGROUND_FOLDERS`)\n",
    "3. Re-run this notebook\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- **If results are good**: Process all files and generate final reports\n",
    "- **If too many false positives**: Use Hard Negative Mining (Section 6)\n",
    "- **If adding new data**: Update config and retrain\n",
    "- **For production use**: Save improved model and document threshold settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
